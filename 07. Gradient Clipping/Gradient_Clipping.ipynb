{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Clipping**\n",
        "\n",
        "Gradient clipping prevents exploding gradients during neural network training by capping gradient values to maintain stability and avoid numerical issues. This is crucial in deep networks and RNNs, where large gradients can destabilize training. There are two methods: clipping by value, which restricts each gradient within a range \\([-v, v]\\), and clipping by norm, which scales gradients if their norm exceeds a threshold. In Keras, this can be set using the `clipvalue` or `clipnorm` parameter in optimizers. Gradient clipping helps stabilize training and improve convergence.\n"
      ],
      "metadata": {
        "id": "460wcR1NTJrq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCAj8tSvOGL-",
        "outputId": "286eb1c3-e3f2-421b-a431-a9234497f945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Import the Fashion MNIST dataset from Keras\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Load the dataset into training and test sets\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
        "\n",
        "# Split the full training set into a smaller training set and a validation set\n",
        "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
        "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1 by dividing by 255\n",
        "X_train, X_valid, X_test = X_train / 255.0, X_valid / 255.0, X_test / 255.0\n",
        "\n",
        "# Compute the mean and standard deviation of the training set\n",
        "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "\n",
        "# Standardize the training, validation, and test sets by subtracting the mean and dividing by the standard deviation\n",
        "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "\n",
        "# Define the class names corresponding to the labels in the Fashion MNIST dataset\n",
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "cyKOS_pEQt6l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary TensorFlow modules\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define a sequential model\n",
        "model = tf.keras.Sequential([\n",
        "    # Flatten layer: Converts each 28x28 image into a 1D array of 784 elements\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "\n",
        "    # use_bias=False means no bias term is added\n",
        "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
        "\n",
        "    #  helps to stabilize and accelerate training by reducing internal covariate shift\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    # introduces non-linearity to the model\n",
        "    tf.keras.layers.Activation(\"relu\"),\n",
        "\n",
        "    # Again, using He initialization and no bias term\n",
        "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
        "\n",
        "    # Another Batch Normalization layer: Normalizes the outputs of the previous layer\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Another Activation layer: Applies the ReLU activation function\n",
        "    tf.keras.layers.Activation(\"relu\"),\n",
        "\n",
        "    # Uses softmax activation function to output probabilities for each class\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Summary of the model: Provides a summary of the model architecture, showing layer types, output shapes, and number of parameters\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXVO_T6rQt4L",
        "outputId": "78986fa9-84fb-413c-988b-6555f48e79b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235200    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 300)               1200      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 300)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30000     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 100)               400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 267810 (1.02 MB)\n",
            "Trainable params: 267010 (1.02 MB)\n",
            "Non-trainable params: 800 (3.12 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# SGD optimizer with a gradient clipping value set to 1.0\n",
        "optimizer = SGD(clipvalue=1.0)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer)\n"
      ],
      "metadata": {
        "id": "6xtizk0dQt2G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 20 epochs\n",
        "model.fit(X_train_scaled, y_train, epochs=10,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sqYfGPnQtzk",
        "outputId": "8ab99155-b53d-429f-c783-3a70751a1569"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.4929 - val_loss: 0.4071\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.4096 - val_loss: 0.3685\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3725 - val_loss: 0.3464\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3422 - val_loss: 0.3408\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.3212 - val_loss: 0.3291\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3031 - val_loss: 0.3307\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2885 - val_loss: 0.3254\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2729 - val_loss: 0.3226\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.2630 - val_loss: 0.3273\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2514 - val_loss: 0.3198\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e186c645720>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tIT3UvQQQtxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wPwXQ_HHQtlR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}