{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**L1 and L2 regularization**\n",
        "\n",
        "Regularization is a technique used in machine learning and neural networks to prevent overfitting and improve the generalization of models. It involves adding a penalty term to the loss function that discourages complex models with high parameter values.\n",
        "\n",
        "**L1 Regularization (Lasso)**:\n",
        "\n",
        " Adds the absolute values of the weights as a penalty term to the loss function. It encourages sparsity in the weights, leading to some weights being exactly zero and thus eliminating irrelevant features.\n",
        "\n",
        "**L2 Regularization (Ridge)**:\n",
        "\n",
        "Adds the squared values of the weights as a penalty term to the loss function. It penalizes large weights and encourages the distribution of weights across all features, preventing them from becoming too large."
      ],
      "metadata": {
        "id": "J-wu4kP50KMI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SDaXZOd0FT9",
        "outputId": "8dec2f47-0943-4ea3-8ad5-d3004cc18648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
        "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
        "\n",
        "# Normalize the pixel values to the range [0, 1]\n",
        "X_train, X_valid, X_test = X_train / 255.0, X_valid / 255.0, X_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class names for the Fashion MNIST dataset\n",
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "TaGnzgAg04vr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "# Define a regularized dense layer with specified parameters\n",
        "RegularizedDense = partial(tf.keras.layers.Dense,\n",
        "                           activation=\"relu\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "\n",
        "# Build the model architecture using the regularized dense layers\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28]),  # Flatten the input images (28x28 pixels)\n",
        "    RegularizedDense(100),  # Regularized dense layer with 100 units\n",
        "    RegularizedDense(100),  # Regularized dense layer with 100 units\n",
        "    RegularizedDense(10, activation=\"softmax\")  # Output layer with 10 units (one for each class) and softmax activation\n",
        "])"
      ],
      "metadata": {
        "id": "ifDZoYt61BlZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Compile the model with specified loss function and optimizer\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)  # SGD optimizer with specified learning rate\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model with the compiled settings\n",
        "history = model.fit(X_train, y_train, epochs=2, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# Display the summary of the model architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmXhy0Qq1Cj5",
        "outputId": "a600c739-805a-42d5-918e-c470f813a638"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 3.1268 - accuracy: 0.7711 - val_loss: 1.8648 - val_accuracy: 0.8222\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 1.4285 - accuracy: 0.8141 - val_loss: 1.1297 - val_accuracy: 0.8148\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89610 (350.04 KB)\n",
            "Trainable params: 89610 (350.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NPdSbO071dqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}