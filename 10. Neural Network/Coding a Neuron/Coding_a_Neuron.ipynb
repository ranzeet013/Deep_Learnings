{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Layer Operations\n",
        "\n",
        "In a neural network, each layer performs a series of operations on the input data to produce the output. These operations can be summarized in three main steps:\n",
        "\n",
        "### 1. Weighted Inputs\n",
        "\n",
        "Each input \\( x_i \\) is multiplied by a corresponding weight \\( w_i \\):\n",
        "- \\( x_1 -> x_1 * w_1 \\)\n",
        "- \\( x_2 -> x_2 * w_2 \\)\n",
        "- And so on for all inputs.\n",
        "\n",
        "### 2. Summation with Bias\n",
        "\n",
        "All the weighted inputs are then summed together along with a bias term \\( b \\):\n",
        "\n",
        " (x_1 * w_1) + (x_2 * w_2) + ... + b\n",
        "\n",
        "### 3. Activation Function\n",
        "\n",
        "The resulting sum is passed through an activation function \\( f \\) to produce the final output \\( y \\):\n",
        "\n",
        " y = f((x_1 * w_1) + (x_2 * w_2) + ... + b)"
      ],
      "metadata": {
        "id": "U7nr9k4-DGcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  # activation function: f(x) = 1 / (1 + e^(-x))\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "epOuMi2LD0rQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron:\n",
        "  def __init__(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def feedforward(self, inputs):\n",
        "    # Weight inputs, add bias, then use the activation function\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    return sigmoid(total)"
      ],
      "metadata": {
        "id": "vJCnh98zD8_K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.array([0, 1]) # w1 = 0, w2 = 1\n",
        "bias = 4                   # b = 4\n",
        "n = Neuron(weights, bias)\n",
        "\n",
        "x = np.array([2, 3])       # x1 = 2, x2 = 3\n",
        "print(n.feedforward(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp4F_vQ5EKsL",
        "outputId": "3cb225e8-5430-4142-952c-020adfae56b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9990889488055994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t8waWXpiEP28"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}